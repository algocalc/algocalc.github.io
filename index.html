<!--  -*- mode: html ; coding: utf-8  -*- ---------------------------------- -->
<html>

<head>

<title>Algo Calc</title>

<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<meta name="robots" content="all">
<meta name="keywords" content="">
<meta name="description" content="">
<meta name="author" content="">

</head>

<!-- <body bgcolor="black" text="white" link="blue">   -->
<!-- <img src="img/34669.jpg" align="right"> -->
<!-- ------------------------------ -->  
<!-- <a href="../../index.html"><b>TO UP</b></a> &nbsp;&nbsp; -->
<!-- <a href="index.html"><b>TO ENGLISH</b></a>  -->
<!-- ------------------------------ -->


<center>
<table width=95%>
<tr><td>

<!-- --------------------------TOP------------------------------------- -->
<table width=100% border=2 cellspacing=0 cellpadding=5>
<tr align=center>
  <td width=15% align="center" bgcolor="cyan"> 
     <!-- <a href="../../README/doc/indru.html"><b>TO UP</b></a> -->
  <td align="center" bgcolor="blue"> 
     <font color="yellow"><b>Algo Calc </b></font>
  <td width=15% align="center" bgcolor="cyan">  
     <!-- <a href="../../README/doc/indru.html"><b>HOME</b></a> <br> -->
</table>
<!-- ------------------------- TOP------------------------------------- -->

<br clear=all>
<br clear=all>
<p><p>

<b><center>     
    <font size=+2 color="red">
Разработка фреймворка глубокого алгоритмического обучения. <br>
    </font>
<br>
С-Петербург,  2019  год, AlgoCalc
</center></b> 

                                                              
<br clear=all>

<hr> <!-- ------------------------------------------------------ -->

<!-- <h2>Содержание:</h2> -->

<!-- <menu> -->

<!-- <li> -->
<!-- <li> -->
<!-- <li> -->
<!-- </menu> -->



<h3>СОДЕРЖАНИЕ</h3> 

<ol><b>
    <a href="#met0"> Введение</a> <br>
    
    <br clear=all>
    <a href="#met1"> 1 Компьютерное зрение, нейронные сети, глубокое обучение</a> <br>
    <a href="#met11">1.1 История развития     </a>  <br>
    <a href="#met12">1.2 Современное состояние</a>  <br>
    <a href="#met13">1.3 Библиотеки глубокого  обучения</a> <br>
    <a href="#met14">1.4 Недостатки метода </a>  <br>
    <a href="#met15">1.5 Будущее технологии</a>  <br>

    <br clear=all>
    <a href="#met2"> 2 Фреймворк глубокого алгоритмического обучения</a> <br>

    <a href="#met21">2.1 Поиск графа вычислений </a><br>
    <a href="#met22">2.2 Стековый язык          </a><br>
    <a href="#met23">2.3 Программная реализация </a><br>
    <a href="#met21">2.4 Численные эксперименты. Методика и программа испытаний. </a><br>
    
    <br clear=all>
    <a href="#met3"> 3 Алгоритмическое исчисление в научно-технических и
                                           фундаментальных исследованиях</a><br>

    <br clear=all>
    <a href="#met4">Заключение</a><br>
</b></ol>

<br clear=all>
<hr> <!-- ------------------------------------------------------ -->

   
<a name="met0"></a><h3>ВВЕДЕНИЕ</h3>

<p align="justify">
  Представлена  мотивировочная часть для  создания фреймворка глубокого алгоритмического
  обучения (ФГАО), план его программной реализации, методика испытания и тестирования,
  а также возможные варианты применения при решении  научно-технических задач  и в
  фундаментальных исследованиях.

<p align="justify">
  Термины «глубокое алгоритмическое обучение» и «алгоритмическое исчисление», насколько
  нам известно, не упоминались ранее в отечественной и зарубежной литературе и вводятся
  впервые. Они означают следующее:
  Глубокое алгоритмическое обучение – следующий этап в развитии глубокого машинного
  обучения сверточных нейронных сетей [1,2], когда  граф вычислений  представляется
  в наиболее общем виде не дифференцируемых операций, и соответственно, к нему уже
  нельзя применять в полной мере метод градиентного спуска, а необходимо использовать
  инновационные методы метаэвристического поиска [3] для установления не только
  параметров программных модулей, но и самого вида графа вычислений.
  Алгоритмическое исчисление – дальнейшее обобщение метода глубокого алгоритмического
  обучения, когда ставится задача поиска инвариантного представления графа вычислений
  в различных программно-библиотечных базисах с целью получения новых знаний в области
  научно-технических и фундаментальных исследований.
  
  Предполагается, что разрабатываемый фреймворк будет, использоваться как практический
  инструмент применения методов глубокого алгоритмического обучения и алгоритмического
  исчисления.


  <a name="met1"></a><h3> 1. КОМПЬЮТЕРНОЕ ЗРЕНИЕ,  НЕЙРОННЫЕ СЕТИ,  ГЛУБОКОЕ ОБУЧЕНИЕ
  </h3>
    
  <a name="met11"></a><h3>1.1 История развития
  </h3>

<p align="justify">
  Алгоритмы компьютерного зрения, исторически, начинали разрабатываться под конкретную
  определенную задачу, и были, практически, не переносимы, даже в смежные предметные
  области. В последующем, разработчики, двигаясь по пути обобщения, стали выделять
  значимые и повторяющиеся методы в библиотеки обработки изображений, выделения
  признаков и их классификации. Параллельно  появилась и начала развиваться технология
  нейронных сетей, сначала в ее первоначальном, примитивном виде с одним или двумя
  полносвязными слоями  «искусственных нейронов». 

<p>
	
<center>
<img src="img/image001.png" width="300" height="350">
<br clear=all><br>
<b>Рисунок 1 – простая нейронная сеть с одним скрытым слоем.</b>
</center>

<p align="justify">
  В 80-е годы на эту технологию возлагались больше надежды, которые, однако, не
  оправдались ввиду большой размерности пространства решений и недостаточности
  вычислительных ресурсов. В промышленности стали применяться более эвристические и
  конкретные методы, такие  как методы опорных векторов на специально выделенных
  признаках с применением линейных и нелинейных классификаторов.
  Однако, с начало 2000-х годов и особенно, начиная, с 2010-х ситуация значительно
  поменялась. Появились новые методики  (сверточные нейронные сети) и мощные
  графические ускорители (GPU), которые хорошо легли на новую парадигму последовательных
  матричных преобразований.


  <a name="met12"></a><h3>1.2 Современное состояние
  </h3>

<p align="justify">
  В последние годы, глубокое обучение (Deep Learning) стало ключевым направлением
  исследований в машинном обучении и, в частности, в задачах компьютерного зрения.
  Часто используют и другие названия, по сути, означающие ту же технологию: глубокая
  нейронная сеть, сверточная сеть, граф вычислений, дифференцируемое программирование.
  Суть технологии заключается в очень ограниченном использовании  слоёв полносвязной
  нейронной сети, которые либо вообще не применяются (полностью сверточные сети)
  либо используются только на конечном этапе, когда размерность пространства признаков
  сильно уменьшена предварительными преобразованиями.
  Вместо этого используется последовательность некоторого набора простых многомерных
  матричных (тензорных) преобразований в виде фильтров, сверток, усреднений,
  суммирований и т.д. Каждое такое последовательное преобразование имеет некоторый
  набор параметров. Например, для свертки 3х3 таких параметров будет, соответственно, 9.
  Для последовательности из двух таких слоев, различных комбинаций параметров будет
  9 * 9 = 81, а для трех уже 9 * 9 * 9 = 729. 

<center>
<img src="img/image003.png" width="600" height="400">
<br clear=all><br>
<b>Рисунок 2 – алгоритм простейшего фильтра-свёртки 3x3.</b>
</center>

	


<p align="justify">
  Современные архитектуры сверточных сетей могут иметь десятки слоев.  Суть преобразований
  в слоях заключается в последовательном выделении иерархических признаков на изображении
  и переходе от более низких уровней абстракции к более высоким.  Задача программиста –
  разработать на основании своих знаний и опыта архитектуру сети для конкретной задачи,
  т.е. определенную последовательность преобразований (вычислительный граф), подобрать
  обучающие наборы данных и запустить процесс машинного обучения. 


<center>
<img src="img/image005.png" width="600" height="300">
<br clear=all><br>
<b>
  Рисунок 3 – пример архитектуры сверточной нейронной сети с двумя финальными
  полносвязными нейронными слоями.
</b>
</center>


  
<p align="justify">
  Задача компьютера на этапе обучения – найти оптимальный набор параметров свёрточной
  сети, а также набор весов полносвязных нейронных слоев, если они были заданны для
  финального этапа графа вычислений. При этом применяются различные методы
  оптимизационного поиска, но в основном используются относительно быстрые методы
  обратного распространения ошибки и коррекции весов в направлении убывания градиента
  передаточной функции по параметрам на каждом слое.
  В результате обучения на наборе данных сеть учится, например, распознавать и
  классифицировать изображения по отдельности или в контексте.


<center>
<img src="img/image007.png" width="500" height="400">
<br clear=all><br>
<b>Рисунок 4 – набор обучающих данных CIFAR-10</b>
</center>

<br>
  
<a name="met13"></a><h3>1.3 Библиотеки глубокого  обучения
</h3>

<p align="justify">
  На текущий момент имеется большое количество программных фреймворков – инструментов
  и библиотек машинного глубокого обучения для задач компьютерного зрения, и их
  число постоянно растет. Однако, большинство из них имеет исследовательский,
  академический характер и мало пригодны для промышленного применения. Большинство
  написано на языке Python, например, – достаточно мощный фреймворк TensorFlow от
  компании Google.
  Представляют также интерес  библиотеки,  написанные на языке Си и имеющие свободный
  доступ к исходным кодам. Таковой является, например, библиотека DarkNet и
  разработанная на ее основе технология компьютерного зрения реального времени YOLO
  – You Only Look Once.



<center>
<img src="img/image009.png" width="500" height="400">
<br clear=all><br>
<b>
  Рисунок 5 – результат работы алгоритма YOLO.
</b>
</center>

<br>
  
  Однако и в этом случае применимость технологии ограничена ее принципиальными
  недостатками, описанными с следующем параграфе.

<a name="met14"></a><h3> 1.4 Недостатки метода</h3>

<p align="justify">
  По сути, вычислительный граф сверточной нейронной сети (СНН) – это простейшая
  программа, состоящая из последовательных геометрических преобразований в многомерном
  матричном пространстве. При этом, для используемого метода градиентного спуска
  важным является гладкость этих преобразований и, соответственно, дифференцируемость.
  Понятно, что таким образом сильно ограничивается набор возможных алгоритмов.
  Например, нельзя использовать любые циклы и условные операторы. Кроме того сам
  метод градиентного спуска применим только для поиска локального минимума, и чтобы
  найти глобальный экстремум необходимы дополнительные алгоритмические корректировки.
  Найденное решение, т.е. архитектура сети и ее параметры обычно фиксированы для
  конкретной задачи и в случае расширения технического задания необходимо, практически,
  начинать структурирование и обучение с нуля или, по крайней мере, с довольно
  глубокого слоя обучения. Нет накопления обобщающих знаний, небольшие изменения в
  ракурсе трехмерных объектов существенно ухудшают статистику распознавания [6].

<a name="met15"></a><h3> 1.5 Будущее технологии</h3>


<p align="justify">
  Будущее развитие видится в направлении обобщения графа вычислений от простых гладких
  матричных преобразований к более универсальным алгоритмам, с выделением наиболее
  продуктивных частей последовательностей в библиотечные процедуры с учетом типизации
  их входных и выходных параметров. Автоматически созданные в процессе машинного
  обучения библиотеки процедур будут являться, по сути, единицами обобщающих знаний в
  предметной области и основой для их дальнейшего неограниченного расширения. Конечно,
  такие алгоритмы, в общем случае, не будут дифференцируемы и, следовательно, для поиска
  их параметров, а также и для поиска самой архитектуры сети нельзя применять методы,
  основанные на предположении о гладкости преобразований. Наоборот, необходимо развивать
  общие эволюционные методы поиска структур и их параметров, например – генетические,
  эволюционные, метаэвристические алгоритмы. При этом важно правильно сформулировать и
  задать модель для таких вычислений. Например, это может быть стековое представление,
  где есть одна глобальная переменная – стек и над последовательностями  операторов
  можно выполнять простые операции преобразований и выделения процедур для библиотеки.
  Конечно, что касается, особенно, приложений компьютерного зрения, то матричные гладкие
  преобразования будут и дальше составлять значительную часть графа вычислений, а значит,
  к отдельным его частям возможно применение разработанных ранее методов градиентного
  спуска.  <br clear=all> 
  Однако, добавление в алгоритмы операторов  управления потоком  данных и вычислений
  может существенно увеличить гибкость и адаптивность  методов машинного обучения.
  Кроме того, представляется, что в этом случае возможно эффективное  совместное
  использование с разработанными ранее алгоритмами обработки изображений и классификации,
  такими как, например,  деревья решений и методы опорных векторов.


<a name="met2"></a><h3>  2. ФРЕЙМВОРК  ГЛУБОКОГО  АЛГОРИТМИЧЕСКОГО ОБУЧЕНИЯ</h3>

<a name="met21"></a><h3> 2.1 Поиск графа вычислений</h3>

<p align="justify">
  Представляется, что для эффективного поиска графа вычислений с параметрами необходимо
  сочетать  стохастические, эволюционные и адаптационные методы.
  Стохастическая оптимизация  – большой класс алгоритмов и методов, которые в той или иной
  степени используют случайность для поиска оптимального решения сложных задач.
  Эволюционные методы – реализация стохастической оптимизации, при которой используются
  базовые принципы биологической эволюции – отбор, мутация и воспроизводство.
  Адаптационные методы -  усиливают эволюционную модель,  предоставляя возможность
  формирования, в процессе машинного обучения, у программных агентов дополнительных
  полезных навыков/библиотек, которые могут быть непосредственно  переданы в следующее
  поколение (не доказанная в природе, но вполне возможная и полезная в программной
  реализации идея Ламарка о наследовании приобретенных признаков).
  В процессе поиска и формирования параметров графа вычислений должна уменьшаться
  стохастическая составляющая алгоритма и увеличиваться адаптационно-детерминированная.
  Т.е., в конечном итоге, мы хотим создать робота-программиста, а точнее коллектив
  роботов-программистов, которые начав работу, в соответствии с заданием
  человека-программиста, по поиску графа вычислений, сначала действуя в
  случайно-хаотичной манере, постепенно, совместно обучаясь, приходят к слаженной,
  целенаправленной и производительной  работе.  При этом полученные навыки/библиотеки
  можно будет сохранять и адаптивно использовать при выполнении следующих заданий.


  <a name="met22"></a><h3>2.2 Стековый язык</h3>

<p align="justify">
  Язык, который предполагается использоваться для представления графа вычислений (т.е. язык на
  котором будут «программировать» роботы-программисты) должен быть максимально простым,
  с минимумом синтаксического сахара и с возможностью динамического
  расширения, например, такой как язык Joy. <br clear=all>
  <b>Joy</b> – стековый функциональный язык конкатенативного программирования, базирующийся
  не на лямбда-исчислении, а на композиции функций, что потенциально позволяет применять
  к программе алгебраические методы преобразований [11].

<a name="met23"></a><h3>2.3 Программная реализация</h3>

<p align="justify">
  Программный комплекс ФГАО, в том числе и описываемый выше стековый язык Joy
  предполагается реализовывать на языке Tcl/Tk – скриптовом языке быстрого
  прототипирования [12].
  Плюсы:  гибкий,  простой, мало синтаксического сахара, нативный GUI, простая
  парадигма  – «все есть строка».

  Минусы: не высокая скорость исполнения, что является обратной стороной его гибкости
  на этапе выполнения, однако, последнее время ведутся работы по созданию специального
  компилятора, что позволит существенно повысить производительность программ  [13].


<a name="met24"></a><h3>2.4 Численные эксперименты. Методика и программа испытаний.</h3>


<a name="met241"></a><h4>2.4.1 Синтетические тесты</h3>

<a name="met242"></a><h4>2.4.2 Тесты на распознавание</h3>



<br><br><br><br><br>



<a name="met3"></a><h3>3. АЛГОРИТМИЧЕСКОЕ  ИСЧИСЛЕНИЕ В НАУЧНО-ТЕХНИЧЕКИХ И ФУНДАМЕНТАЛЬНЫХ ИССЛЕДОВАНИЯХ</h3>


<a name="met31"></a><h3>3.1 Введение понятия алгоритмического исчисления</h3>

<a name="met31"></a><h3>3.2 Программа исследований</h3>



<br><br><br><br><br>

<a name="met4"></a><h3>ЗАКЛЮЧЕНИЕ</h3>

<p align="justify">
  Рассмотренный выше проект создания и развития фреймворка глубокого алгоритмического
  обучения (ФГАО) позволит, в случае его успешной реализации,  существенно продвинуться
  вперед на этапе формирования новых компьютерных и технологических моделей.
  В дальнейшем, применение ФГАО в контексте алгоритмического исчисления позволит получать
  новые знания в развитии алгоритмических методов научно-технических и фундаментальных
  исследований.        


<a name="met5"></a><h3>СПИСОК ИСПОЛЬЗУЕМЫХ ИСТОЧНИКОВ</h3>

<br><br>

1. Франсуа Шолле  «Глубокое обучение на Python», ПИТЕР, 2018 <p> 

2. С.Николенко, А.Кадурин, Е.Архангельская «Глубокое обучение. Погружение в мир
нейронных сетей», ПИТЕР, 2018 <p> 

3. Sean Luke,  “Essentials of  Metaheuristics”, Department of Computer  Science,
George Mason University, Second Edition, Online Version 2.2, October 2015 <p> 

4. . <p> 

5. . <p> 

6. Michael A. Alcon, etc, “Strike (with) a Pose: Neural Networks Are Easily Fooled
by Strange Poses of Familiar Objects”, ArXiv 2018, https://arxiv.org/abs/1811.11553  <p>

7. Гладков Л.А,  Курейчик  В.В., Курейчик  В.М.  Генетические алгоритмы. ФИЗМАТЛИТ, 2010  <p>

8. Генетическое программирование [Электронный ресурс] : Материал из Википедии :
https://ru.wikipedia.org/?oldid=81075569 <p>

9. Корухова Ю.С.,  «Система автоматического синтеза функциональных программ»,
Диссертация на соискание учёной степени кандидата физ.-мат. наук,  МГУ, 2005 <p>

10.   Mehran Maghoumi,  “Real-Time Automatic Object Classification and Tracking
using Genetic Programming and NVIDIA CUDA” , 2014 <p>

11.   Joy (язык программирования) [Электронный ресурс] : Материал из Википедии:
  <a href="http://ru.wikipedia.org/?oldid=78541365">   http://ru.wikipedia.org/?oldid=78541365</a>   <p>

12. Tcl [Электронный ресурс] : Материал из Википедии:
<a href="http://ru.wikipedia.org/?oldid=81094010"> http://ru.wikipedia.org/?oldid=81094010</a> <p>

13. Donal Fellow, “Tcl/Tk Status  July 2018”, Conference EuroTcl2018,
<a href="http://www.eurotcl.eu/presentations/EuroTcl2018-Fellows-TclTkStatusJuly2018-Tclquadcode.pdf">
http://www.eurotcl.eu/presentations/EuroTcl2018-Fellows-TclTkStatusJuly2018-Tclquadcode.pdf</a> <p>

14. GAUL - библиотека оптимизационных алгоритмов на языке СИ.
    <a href="http://gaul.sourceforge.net">http://gaul.sourceforge.net</a> <p>



<!-- ---------------------------BOTTOM---------------------------------- -->
<br clear=all><br>
<table width=100% border=2 cellspacing=0 cellpadding=5>
<tr align=center>
  <td width=15% align="center" bgcolor="cyan"> 
     <!-- <a href="../../README/doc/indru.html"><b>TO UP</b></a> -->
  <td align="center" bgcolor="blue"> 
     <b><font color="yellow">Algo Calc &nbsp; ( </font> 
     <font color="yellow" size=-1>
<!-- hhmts start -->
Last modified: Tue Feb  5 22:26:47 MSK 2019
<!-- hhmts end -->
     </font><font color="yellow">)</font></b>
     <td width=15% align="center" bgcolor="cyan">  
     <!-- <a href="../../README/doc/indru.html"><b>HOME</b></a> <br> -->
</table>
<!-- ---------------------------BOTTOM---------------------------------- -->


</td></tr>
</table>
</center>


</body>
</html>
